# Using RadVLM for Grounding Dataset Creation & veRL GRPO Training

## üéØ **TL;DR**: RadVLM already has everything you need!

RadVLM already includes:
- ‚úÖ **mAP evaluation** for grounding tasks
- ‚úÖ **veRL dataset creation** with IoU rewards
- ‚úÖ **Train/test splits** for all grounding datasets
- ‚úÖ **Comprehensive evaluation pipeline**

## üìã **Quick Start**

### 1. **Create veRL Grounding Dataset**

```bash
# Use existing infrastructure to create train/test splits
python radvlm/data/create_comprehensive_grounding_verl.py \
    --data_dir /path/to/datasets \
    --output_dir ./grounding_datasets \
    --splits train test
```

**Output:**
- `train.parquet` - Training dataset for veRL GRPO
- `test.parquet` - Test dataset for evaluation

### 2. **Train with veRL GRPO**

The generated parquet files follow veRL's exact format:
```python
{
    "data_source": "MS-CXR",
    "prompt": [{"role": "user", "content": "Please provide bounding box coordinates for: enlarged cardiac silhouette"}],
    "ability": "phrase_grounding",
    "reward_model": {
        "style": "iou",
        "ground_truth": [[0.2, 0.3, 0.8, 0.7]]
    },
    "extra_info": {...}
}
```

### 3. **Evaluate with RadVLM (mAP included!)**

```bash
# RadVLM already has mAP evaluation!
accelerate launch --num_processes=4 radvlm.evaluation.evaluate_instructions \
    --task phrase_grounding \
    --model_name your_trained_model_path
```

**This automatically computes:**
- mAP@0.5 (default)
- Average IoU
- Visualization of predictions vs ground truth

## üîß **Advanced Evaluation**

### **Multiple IoU Thresholds**
Edit `radvlm/evaluation/compute_metrics_tasks.py` to add more thresholds:

```python
def evaluate_boxes(output_list, iou_thresholds=None, avg_iou=False):
    if iou_thresholds is None:
        iou_thresholds = [0.3, 0.5, 0.7]  # Add your preferred thresholds
```

### **Evaluate All Grounding Tasks**
```bash
# Region grounding (Chest ImaGenome)
accelerate launch --num_processes=4 radvlm.evaluation.evaluate_instructions \
    --task region_grounding \
    --model_name your_model

# Abnormality grounding (VinDr-CXR)
accelerate launch --num_processes=4 radvlm.evaluation.evaluate_instructions \
    --task abnormality_grounding \
    --model_name your_model

# Phrase grounding (MS-CXR)
accelerate launch --num_processes=4 radvlm.evaluation.evaluate_instructions \
    --task phrase_grounding \
    --model_name your_model
```

## üìä **What You Get**

### **Evaluation Metrics** (already implemented):
- **mAP@0.5**: Mean Average Precision at 0.5 IoU threshold
- **avg_iou**: Average IoU across all predictions
- **Visualization**: Bounding box overlays (green=GT, red=prediction)

### **Dataset Coverage**:
| Dataset | Task | Train Samples | Test Samples | Split Method |
|---------|------|---------------|--------------|--------------|
| MS-CXR | Phrase grounding | ~971 | ~189 | MIMIC-CXR splits |
| VinDr-CXR | Abnormality grounding | ~16,089 | ~2,108 | Official train/test |
| PadChest-GR | Phrase grounding | ~4,478 | ~validation | train/valid splits |

## üöÄ **Your Workflow**

1. **Create datasets**: Use the adapted script for train/test splits
2. **GRPO training**: Use train.parquet with veRL
3. **Evaluation**: Use existing RadVLM evaluation with mAP
4. **Iteration**: Leverage comprehensive metrics for model improvement

## üîç **Key Advantages**

- **Proven infrastructure**: RadVLM's evaluation is already validated
- **Comprehensive metrics**: mAP, IoU, visualization all included
- **Multiple datasets**: Combined grounding datasets for robust training
- **veRL compatibility**: Exact format matching for seamless integration

## üõ† **Implementation Notes**

### **Existing Files You'll Use**:
- `radvlm/evaluation/evaluate_instructions.py` - Main evaluation pipeline
- `radvlm/evaluation/compute_metrics_tasks.py` - mAP calculation
- `radvlm/data/create_verl_dataset_llava.py` - veRL format generation

### **Dataset Split Handling**:
- **MS-CXR**: Uses MIMIC-CXR's official train/test splits
- **VinDr-CXR**: Has native train/test splits
- **PadChest**: Uses train/validation (maps to train/test)

### **Coordinate Format**:
- All bounding boxes are normalized [x1, y1, x2, y2] format
- IoU calculation handles multiple boxes per sample
- Automatic extraction from various text formats

## üìà **Expected Results**

Based on RadVLM paper results:
- **MS-CXR phrase grounding**: ~0.3-0.5 mAP@0.5
- **VinDr-CXR abnormality grounding**: ~0.4-0.6 mAP@0.5
- **Combined dataset**: Robust performance across tasks

Your approach of combining datasets + IoU rewards + GRPO training should improve these baselines significantly!